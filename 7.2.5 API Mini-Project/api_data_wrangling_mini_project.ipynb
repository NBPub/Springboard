{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resubmission\n",
    "\n",
    "I found some probable misinterpretations when I reviewed my work, which I have detailed below. \n",
    "If an answer is still incorrect due to *performing the* ***incorrect*** *calculation* and not due to *performing the calculation* ***incorrectly***, then can you please provide the proper interpretation of the question on the grading form? \n",
    "\n",
    "Thank you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Answers](#Exercises)\n",
    "\n",
    "*data returned from API call saved as JSON `data.json` and can be loaded to save a call*\n",
    "\n",
    " - Resubmission Review\n",
    "   - #4, I believe this was a simple misread.\n",
    "     - > What was the largest change in any one day (based on High and Low price)?\n",
    "     - correction: high - low for each day, then max change\n",
    "     - \n",
    "   - #5, possible misinterpretation. I'm still unsure of the correct way to read question, I tried two new approaches.\n",
    "     - > What was the largest change between any two days (based on Closing Price)?\n",
    "     - ~~correction 1: largest overall change in closing price for the year (range)~~\n",
    "     - correction 2: largest change for consecutive closing prices (day+1 - day)\n",
    "       - consecutive days and consecutive data points yielded the same answer\n",
    "   - #7, again unsure of my error. I tried treating the non-trading days to have `0` trading volume to change the median calculation\n",
    "     - > (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)\n",
    "     - previous try: sort daily trading volume data, take middle value for median\n",
    "     - ~~correction: prepend sorted data with 0's such that data contains 365 trading volume data points, take middle value for median~~\n",
    "     - correction 2: remove non-trading days, days without opening price values. From 255 days to 252 days.\n",
    "       - there is still a discrepancy with the 251 trading days found from external sources for 2017\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as file:\n",
    "    struct = json.loads(file.read()) \n",
    "    \n",
    "# keys saved as strings and note datetime objects, would have to convert back\n",
    "# datetime.strptime(<key>,'%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from https://data.nasdaq.com/ (formerly Quandl API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the https://data.nasdaq.com/ website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:\n",
    "\n",
    "*Note*: Use a `.env` file and put your key in there and `python-dotenv` to access it in this notebook. \n",
    "\n",
    "The code below uses a key that was used when generating this project but has since been deleted. Never submit your keys to source control. There is a `.env-example` file in this repository to illusrtate what you need. Copy that to a file called `.env` and use your own api key in that `.env` file. Make sure you also have a `.gitignore` file with a line for `.env` added to it. \n",
    "\n",
    "The standard Python gitignore is [here](https://github.com/github/gitignore/blob/master/Python.gitignore) you can just copy that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "print(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I removed my key prior to submission. It will not be located within an \".env\" file within the repo. Please use your own key when evaluating my work, thanks.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '...' # KEY REMOVED BEFORE SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the relevant modules\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: API's can change a bit with each version, for this exercise it is reccomended to use the nasdaq api at `https://data.nasdaq.com/api/v3/`. This is the same api as what used to be quandl so `https://www.quandl.com/api/v3/` should work too.\n",
    "\n",
    "Hint: We are looking for the `AFX_X` data on the `datasets/FSE/` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, call the Nasdaq API and pull out a small sample of the data (only one day) to get a glimpse\n",
    "# into the JSON structure that will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = f'https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X.json?start_date=2020-11-30&end_date=2020-12-01&api_key={API_KEY}'\n",
    "r = requests.get(URL)\n",
    "if r.status_code == 200:\n",
    "    data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'id': 10095370,\n",
       "  'dataset_code': 'AFX_X',\n",
       "  'database_code': 'FSE',\n",
       "  'name': 'Carl Zeiss Meditec (AFX_X)',\n",
       "  'description': 'Stock Prices for Carl Zeiss Meditec (2020-11-02) from the Frankfurt Stock Exchange.<br><br>Trading System: Xetra<br><br>ISIN: DE0005313704',\n",
       "  'refreshed_at': '2020-12-01T14:48:09.907Z',\n",
       "  'newest_available_date': '2020-12-01',\n",
       "  'oldest_available_date': '2000-06-07',\n",
       "  'column_names': ['Date',\n",
       "   'Open',\n",
       "   'High',\n",
       "   'Low',\n",
       "   'Close',\n",
       "   'Change',\n",
       "   'Traded Volume',\n",
       "   'Turnover',\n",
       "   'Last Price of the Day',\n",
       "   'Daily Traded Units',\n",
       "   'Daily Turnover'],\n",
       "  'frequency': 'daily',\n",
       "  'type': 'Time Series',\n",
       "  'premium': False,\n",
       "  'limit': None,\n",
       "  'transform': None,\n",
       "  'column_index': None,\n",
       "  'start_date': '2020-11-30',\n",
       "  'end_date': '2020-12-01',\n",
       "  'data': [['2020-12-01',\n",
       "    112.2,\n",
       "    112.2,\n",
       "    111.5,\n",
       "    112.0,\n",
       "    None,\n",
       "    51.0,\n",
       "    5703.0,\n",
       "    None,\n",
       "    None,\n",
       "    None],\n",
       "   ['2020-11-30',\n",
       "    111.0,\n",
       "    113.6,\n",
       "    111.0,\n",
       "    112.1,\n",
       "    None,\n",
       "    315.0,\n",
       "    35111.5,\n",
       "    None,\n",
       "    None,\n",
       "    None]],\n",
       "  'collapse': None,\n",
       "  'order': None,\n",
       "  'database_id': 6129}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the JSON structure of the object you created, and take note of how nested it is,\n",
    "# as well as the overall structure\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are your tasks for this mini project:\n",
    "\n",
    "1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).\n",
    "2. Convert the returned JSON object into a Python dictionary.\n",
    "3. Calculate what the highest and lowest opening prices were for the stock in this period.\n",
    "4. What was the largest change in any one day (based on High and Low price)?\n",
    "5. What was the largest change between any two days (based on Closing Price)?\n",
    "6. What was the average daily trading volume during this year?\n",
    "7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data comes as list for each day within `\"data\"` key. List contains, in order (see `\"column_names\"` key\n",
    " - date \"YYYY-MM-DD\"\n",
    " - Opening price\n",
    " - High\n",
    " - Low\n",
    " - Close\n",
    " - Change\n",
    " - Traded Volume\n",
    " - Turnover\n",
    " - Last Price of the Day\n",
    " - Daily Traded Units\n",
    " - Daily Turnover\n",
    "```\n",
    "  ['2020-11-30',\n",
    "    111.0,\n",
    "    113.6,\n",
    "    111.0,\n",
    "    112.1,\n",
    "    None,\n",
    "    315.0,\n",
    "    35111.5,\n",
    "    None,\n",
    "    None,\n",
    "    None]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).\n",
    "2. Convert the returned JSON object into a Python dictionary.\n",
    "\n",
    "*dataset collected in cell below, individual column data extracted into lists later*\n",
    "\n",
    "*`json` and `requests` packages imported above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_params = 'start_date=2017-01-01&end_date=2017-12-31&order=asc' # collapse to daily has no effect on returned data\n",
    "key = f'&api_key={API_KEY}'\n",
    "\n",
    "URL = f'https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X.json?{call_params}{key}'\n",
    "r = requests.get(URL)\n",
    "if r.status_code == 200:\n",
    "    r = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'dataset_code', 'database_code', 'name', 'description', 'refreshed_at', 'newest_available_date', 'oldest_available_date', 'column_names', 'frequency', 'type', 'premium', 'limit', 'transform', 'column_index', 'start_date', 'end_date', 'data', 'collapse', 'order', 'database_id'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['dataset'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data\n",
    "# github notebook display does not allow for scrollable outputs, I will comment out long outputs prior to submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Date \t~\t 2017-01-02\n",
      "1 Open \t~\t 34.99\n",
      "2 High \t~\t 35.94\n",
      "3 Low \t~\t 34.99\n",
      "4 Close \t~\t 35.8\n",
      "5 Change \t~\t None\n",
      "6 Traded Volume \t~\t 44700.0\n",
      "7 Turnover \t~\t 1590561.0\n",
      "8 Last Price of the Day \t~\t None\n",
      "9 Daily Traded Units \t~\t None\n",
      "10 Daily Turnover \t~\t None\n"
     ]
    }
   ],
   "source": [
    "for i,val in enumerate(r['dataset']['column_names']):\n",
    "    print(i,val,'\\t~\\t', r['dataset']['data'][0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r['dataset']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes is mostly none, skip\n",
    "# 3 None for opens, skip for now to allow max() operation on list\n",
    "\n",
    "opens = []\n",
    "closes = []\n",
    "highs = []\n",
    "lows = []\n",
    "vols = []\n",
    "# changes = []\n",
    "\n",
    "for datum in data:\n",
    "    if datum[1]:\n",
    "        opens.append(datum[1]) \n",
    "    highs.append(datum[2])\n",
    "    lows.append(datum[3]) \n",
    "    closes.append(datum[4])\n",
    "    # changes.append(datum[5])\n",
    "    vols.append(int(datum[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing opens: 0 out of 252\n",
      "Missing highs: 0 out of 255\n",
      "Missing lows: 0 out of 255\n",
      "Missing closes: 0 out of 255\n",
      "Missing vols: 0 out of 255\n"
     ]
    }
   ],
   "source": [
    "print('Missing opens:', opens.count(None), 'out of', len(opens))\n",
    "print('Missing highs:', highs.count(None), 'out of', len(highs))\n",
    "print('Missing lows:', lows.count(None), 'out of', len(lows))\n",
    "print('Missing closes:', closes.count(None), 'out of', len(closes))\n",
    "print('Missing vols:', vols.count(None), 'out of', len(vols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [wikipedia](https://en.wikipedia.org/wiki/Trading_day#:~:text=after%20Thanksgiving%20Day), \n",
    "there were 251 trading days in 2017. I do not know how to interpret missing or extra dates. I'd guess maybe the opens are the real days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/14/17 null opening value. Was this a trading day?\n",
      "{'open': None, 'high': 42.48, 'low': 41.985, 'close': 42.2, 'volume': 88416}\n",
      "04/17/17 null opening value. Was this a trading day?\n",
      "{'open': None, 'high': 42.48, 'low': 41.985, 'close': 42.2, 'volume': 88416}\n",
      "05/01/17 null opening value. Was this a trading day?\n",
      "{'open': None, 'high': 42.245, 'low': 41.655, 'close': 41.72, 'volume': 86348}\n"
     ]
    }
   ],
   "source": [
    "# Structured Data\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "struct = {}\n",
    "\n",
    "for datum in data:\n",
    "    stamp = datetime.strptime(datum[0],'%Y-%m-%d')\n",
    "    struct[stamp] = {\n",
    "        'open':datum[1],\n",
    "        'high':datum[2],\n",
    "        'low':datum[3],\n",
    "        'close':datum[4],\n",
    "        'volume':int(datum[6])\n",
    "    }\n",
    "    if not datum[1]:\n",
    "        print(stamp.strftime('%x'), 'null opening value. Was this a trading day?')\n",
    "        print(struct[stamp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*these days will be removed prior to median calculation for Q7*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "3. Calculate what the highest and lowest opening prices were for the stock in this period.\n",
    "\n",
    "**The maximum opening price for 2017 was \\\\$53.11 and the minimum was \\\\$34.0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum opening price for 2017 was $53.11 and the minimum was $34.0.\n"
     ]
    }
   ],
   "source": [
    "print(f'The maximum opening price for 2017 was ${max(opens)} and the minimum was ${min(opens)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "4. What was the largest change in any one day (based on High and Low price)?\n",
    "\n",
    "**The largest change in 2017 based on high and low price for a day was \\\\$2.81**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_change = [highs[i]-lows[i] for i in range(len(highs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18999999999999773, 2.8100000000000023)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_change_bounds = (min(day_change),max(day_change))\n",
    "day_change_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*unstructured data should be fine, as each pair of high/low values comes from the same date*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "5. What was the largest change between any two days (based on Closing Price)?\n",
    "\n",
    "**The largest change between any two consecutive days was $-2.56 dollars, and the largest growth was \\\\$1.72**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# two days?\n",
    "by_date = []\n",
    "for day in struct.keys():\n",
    "    future = day+timedelta(days=1)\n",
    "    if future in struct.keys():\n",
    "        by_date.append(struct[future]['close'] - struct[day]['close'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, -2.559999999999995, 1.7199999999999989)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(by_date), min(by_date), max(by_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Some other ideas below. . .*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two points?\n",
    "by_point = [closes[i+1]-closes[i] for i in range(len(closes)-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, -2.559999999999995, 1.7199999999999989)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(by_point), min(by_point), max(by_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.03"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# largest overall change\n",
    "# **The largest change between any two days' Closing Prices was $19.03 (range of the closing prices over the year).**\n",
    "close_change = max(closes)-min(closes)\n",
    "close_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "6. What was the average daily trading volume during this year?\n",
    "\n",
    "The average trading volume during 2017 was **32,265** when considering the total and each day of the year. The average when considering only the 255 days with daily trading volume data was **89,124.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62264.94794520548 89124.33725490196 volume data for 255 days\n"
     ]
    }
   ],
   "source": [
    "avg_vol = sum(vols)/365\n",
    "avg_vol2 = sum(vols)/len(vols)\n",
    "\n",
    "print(avg_vol, avg_vol2, 'volume data for', len(vols), 'days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)\n",
    "\n",
    "The median trading volume during 2017 was **$74,723.5** when considering only the 252 days with non-empty values for \"Opening\", which I interpreted as days with actual trading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation Two* - remove days without opening values, as they might not have been trading days. This leaves 252 values. \n",
    "Recall, according to [wikipedia](https://en.wikipedia.org/wiki/Trading_day#:~:text=after%20Thanksgiving%20Day), \n",
    "there were 251 trading days in 2017.\n",
    "\n",
    " - null opening values\n",
    "   - 04/14/17\n",
    "   - 04/17/17\n",
    "   - 05/01/17\n",
    " - no duplicate dates were found in the data\n",
    " - could any other date be removed?\n",
    "   - did not find any reason to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate date check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = struct.copy()\n",
    "vols2 = vols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no duplicate dates\n",
    "dates.keys() == set(dates.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 250\n"
     ]
    }
   ],
   "source": [
    "# certain days can have the same trading volume\n",
    "print(len(vols2), len(set(vols2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find dates with \"null\" opening value, see above, and their indices\n",
    "# remove from trading volume list and structured data\n",
    "\n",
    "inds = {}\n",
    "for null_day in ['2017-04-14','2017-04-17','2017-05-01']:\n",
    "    dt = datetime.strptime(null_day,'%Y-%m-%d')\n",
    "    inds[list(dates.keys()).index(dt)] = dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85, 75, 74]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(inds.keys())[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 days with volume data before clean\n",
      "255 days with structured volume data before clean\n",
      "252 days with volume data after clean\n",
      "252 days with structured volume data after clean\n"
     ]
    }
   ],
   "source": [
    "print(len(vols2), 'days with volume data before clean')\n",
    "print(len(dates.keys()), 'days with structured volume data before clean')\n",
    "\n",
    "# perform in reverse order such that indices do not lose correspondence to dates\n",
    "for ind in list(inds.keys())[::-1]:\n",
    "    vols2.pop(ind)\n",
    "    dates.pop(inds[ind])\n",
    "    \n",
    "print(len(vols2), 'days with volume data after clean')\n",
    "print(len(dates.keys()), 'days with structured volume data after clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consecuitive repeates in volume data?\n",
    "\n",
    "for i,val in enumerate(vols2[:-1]):\n",
    "    if vols2[i+1] == val:\n",
    "        print('repeate volume data for')\n",
    "        print(list(dates.keys())[i], list(dates.keys())[i+1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median daily trading volume: 74723.5\n"
     ]
    }
   ],
   "source": [
    "# sort and find median\n",
    "# average middle two values, as there are now an even number of days\n",
    "vols2.sort()\n",
    "print('median daily trading volume:', sum(vols2[125:127])/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation One* - simple median of datatset (255 values)\n",
    "\n",
    "The median trading volume during 2017 was **76,600** when considering only the 255 days with trading volume data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_vols = vols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_vols.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median daily trading volume: 76600\n"
     ]
    }
   ],
   "source": [
    "print('median daily trading volume:', sorted_vols[round(len(sorted_vols)/2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrect\n",
    "**4,5,7** incorrect with first submission. I believe I may have simply misinterpreted **4** and **5**. Original submissions with added notes below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I thought this meant day-to-day change for highs as one group, and for lows as another. not high vs low for a given day***\n",
    "\n",
    "---\n",
    "4. What was the largest change in any one day (based on High and Low price)?\n",
    "\n",
    "**The largest change in 2017 based on high price was -\\\\$2.81 and was -\\\\$3.44 based on low price.**\n",
    "\n",
    "*I used the API to return price differences instead of calculating them from the original dataset. The largest change considered both negative and positive changes, and in this case they were both negative values.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_params = 'start_date=2017-01-01&end_date=2017-12-31&order=asc&collapse=daily&transform=diff&column_index=2'\n",
    "key = f'&api_key={API_KEY}'\n",
    "\n",
    "URL = f'https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X.json?{call_params}{key}'\n",
    "r4a = requests.get(URL)\n",
    "if r4a.status_code == 200:\n",
    "    r4a = r4a.json()\n",
    "data4a = r4a['dataset']['data']\n",
    "\n",
    "call_params = 'start_date=2017-01-01&end_date=2017-12-31&order=asc&collapse=daily&transform=diff&column_index=3'\n",
    "key = f'&api_key={API_KEY}'\n",
    "\n",
    "URL = f'https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X.json?{call_params}{key}'\n",
    "r4b = requests.get(URL)\n",
    "if r4b.status_code == 200:\n",
    "    r4b = r4b.json()\n",
    "data4b = r4b['dataset']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_changes = [val[1] for val in data4a]\n",
    "high_change_bounds = (min(high_changes),max(high_changes))\n",
    "\n",
    "low_changes = [val[1] for val in data4b]\n",
    "low_change_bounds = (min(low_changes),max(low_changes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(high_change_bounds) # (-2.81, 2.46)\n",
    "print(low_change_bounds) # (-3.44, 1.61)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*any two days should mean the biggest overall change, not specified as any two-day* ***period***\n",
    "\n",
    "---\n",
    "5. What was the largest change between any two days (based on Closing Price)?\n",
    "\n",
    "**The largest two-day change in 2017 based on closing price was -\\\\$3.15**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_day_change_close = [closes[i+2]-closes[i] for i in range(len(closes)-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-3.1499999999999986, 2.280000000000001)\n"
     ]
    }
   ],
   "source": [
    "two_day_change_bounds = (min(two_day_change_close),max(two_day_change_close))\n",
    "print(two_day_change_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I think sorting and taking the middle value was the correct approach. I tried considering days without data to have `0` trading volume to get a different answer.***\n",
    "\n",
    "---\n",
    "7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)\n",
    "\n",
    "The median trading volume during 2017 was **76,600**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_vols = vols.copy()\n",
    "sorted_vols.sort()\n",
    "print('median daily trading volume:', sorted_vols[round(len(sorted_vols)/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7635eb1b9d0fe97add78a7368b6b431c09bb8ad5c42e437d64abdd99821c31ae"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
